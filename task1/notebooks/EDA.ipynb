{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1210d8-9d7a-4cea-9d71-97e2f5f9f58c",
   "metadata": {},
   "source": [
    "# Marine Datathon 2022: Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013dd1cb-3177-4511-8591-e2e40bb118d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e8f382-9e23-4684-9a89-c243a76a2735",
   "metadata": {},
   "source": [
    "## Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb8059-e42a-42b0-9ea2-93a264c64212",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = \"../dataset/labels.csv\"\n",
    "audio_dir = \"../dataset/audios\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee70459",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b585ca1-0874-4970-8a6f-a2a3bddba9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv(annotations_path)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e86b88",
   "metadata": {},
   "source": [
    "## Labels Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ea7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccadc02",
   "metadata": {},
   "source": [
    "Show the count of events durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "plt.xlabel(\"Duration (seconds)\")\n",
    "plt.ylabel(\"Count\")\n",
    "annotations.duration.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9715b9e3",
   "metadata": {},
   "source": [
    "Drop **click** labels with high duration (> 290 seconds). They are annotation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aea72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_mask = annotations.duration > 290\n",
    "drop_mask &= annotations.label == \"click\"\n",
    "annotations = annotations[~drop_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00c1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.sort_values(\"duration\").tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c86db2",
   "metadata": {},
   "source": [
    "Show the new distribution without wrong labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 10))\n",
    "plt.xlabel(\"Duration (seconds)\")\n",
    "plt.ylabel(\"Count\")\n",
    "annotations.duration.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[[\"start\", \"duration\", \"end\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02829a37",
   "metadata": {},
   "source": [
    "Check the total duration of audio data by label (**in minutes**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.groupby(\"label\").duration.sum() / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02829a37",
   "metadata": {},
   "source": [
    "Check the mean duration of each audio event by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4410edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.groupby(\"label\").duration.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89259401",
   "metadata": {},
   "source": [
    "### Test labels extraction for Sound Event Detection (SED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a02682",
   "metadata": {},
   "source": [
    "Prepare a function to convert all the annotations from one audio into a 2D matix of (# labels, frames) to encode the labels at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad513a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels = annotations.label.value_counts().index\n",
    "n_labels = len(sorted_labels)\n",
    "labels2idx = {l: i for i, l in enumerate(sorted_labels)}\n",
    "\n",
    "\n",
    "def labels_to_mask(\n",
    "    audio_annot: pd.DataFrame,\n",
    "    frame_size: int,\n",
    "    hop_size: int,\n",
    ") -> torch.Tensor:\n",
    "    # Load the audio\n",
    "    signal, sample_rate = torchaudio.load(os.path.join(audio_dir, f\"{audio_annot.name}.wav\"))\n",
    "\n",
    "    # Prepare the mask 2D matrix (labels, frames)\n",
    "    n_frames = int((signal.shape[-1] - frame_size) / hop_size) + 1\n",
    "    mask = torch.zeros((n_labels, n_frames))\n",
    "    # Compute some utility values\n",
    "    sample_time = 1 / sample_rate\n",
    "    frame_time = sample_time * frame_size\n",
    "    for idx, row in audio_annot.iterrows():\n",
    "        start_frame = int(row.start / frame_time)\n",
    "        end_frame = int(row.end / frame_time)\n",
    "        mask[labels2idx[row.label], start_frame:end_frame] += 1\n",
    "        \n",
    "    return mask.bool().int()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4313d4",
   "metadata": {},
   "source": [
    "Apply the mask extraction (for each audi file) from the annotations temporal labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c36850",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 47  # Sample to select\n",
    "FRAME_SIZE = 1024\n",
    "HOP_SIZE = 512\n",
    "\n",
    "SOURCE_SAMPLE_RATE = 50000\n",
    "sample_duration = 1 / SOURCE_SAMPLE_RATE\n",
    "frame_duration = sample_duration * FRAME_SIZE\n",
    "hop_duration = sample_duration * HOP_SIZE\n",
    "print(f\"{sample_duration=}s\")\n",
    "print(f\"{frame_duration=}s\")\n",
    "print(f\"{hop_duration=}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_masks = annotations.groupby(\"path\").apply(lambda x: labels_to_mask(x, FRAME_SIZE, HOP_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mask(mask, labels):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.imshow(mask, aspect=\"auto\", interpolation=\"none\", cmap=\"jet\")\n",
    "    plt.yticks(range(len(labels)), labels=labels)\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b99742",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_audio_id = audio_masks.index[sample_idx]\n",
    "\n",
    "plot_mask(audio_masks.iloc[sample_idx], sorted_labels)\n",
    "\n",
    "# Show the audio annotations to compare\n",
    "display(annotations[annotations.path == audio_masks.index[sample_idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154e768",
   "metadata": {},
   "source": [
    "## Audio visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3326e3ee-92e7-447b-a96f-e6c25467d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sample_rate = torchaudio.load(os.path.join(audio_dir, f\"{selected_audio_id}.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.plot(time_axis, waveform[0], linewidth=1)\n",
    "    plt.grid(True)\n",
    "    plt.suptitle(\"waveform\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\", interpolation=\"antialiased\"):\n",
    "    plt.figure(figsize=(30, 10))\n",
    "    plt.title(title or \"Spectrogram (db)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(\"frame\")\n",
    "    amplitude_2_DB = torchaudio.transforms.AmplitudeToDB()\n",
    "    plt.imshow(amplitude_2_DB(specgram), origin=\"lower\", aspect=\"auto\", interpolation=interpolation)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e962d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(signal, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_transform = torchaudio.transforms.Spectrogram(n_fft=FRAME_SIZE, hop_length=HOP_SIZE, center=False)\n",
    "spectrogram = spec_transform(signal)\n",
    "plot_spectrogram(spectrogram[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec_transform = torchaudio.transforms.MelSpectrogram(sample_rate=50000, n_fft=FRAME_SIZE, hop_length=HOP_SIZE, center=False, n_mels=64)\n",
    "mel_spectrogram = melspec_transform(signal)\n",
    "plot_spectrogram(mel_spectrogram[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a043e2",
   "metadata": {},
   "source": [
    "## Chunks preprocessing\n",
    "\n",
    "Experiment with the frame chunks extraction from the spectrograms and labels mask to create the training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 512\n",
    "spec_chunks = librosa.util.frame(spectrogram, frame_length=n_frames, hop_length=n_frames // 2)\n",
    "mask_chunks = librosa.util.frame(audio_masks.iloc[sample_idx], frame_length=n_frames, hop_length=n_frames // 2)\n",
    "print(f\"{spec_chunks.shape=}\")\n",
    "print(f\"{mask_chunks.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f9f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_idx = 23\n",
    "spec_chunk = spec_chunks[:, :, :, chunk_idx]\n",
    "mask_chunk = mask_chunks[:, :, chunk_idx]\n",
    "print(f\"{spec_chunk.shape=}\")\n",
    "print(f\"{mask_chunk.shape=}\")\n",
    "plot_spectrogram(torch.from_numpy(spec_chunk[0]))\n",
    "plot_mask(torch.from_numpy(mask_chunk), sorted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17dd4dd",
   "metadata": {},
   "source": [
    "Test the mask chunk combination to create the 1D one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e08019",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_mask_chunk = mask_chunk.sum(axis=1)  # Aggregate the frames\n",
    "chunk_label = acc_mask_chunk.astype(bool).astype(np.uint8)\n",
    "#chunk_label = acc_mask_chunk / mask_chunk.shape[1]\n",
    "chunk_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('audio')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2252593e89e7d3aa9f5262b6f0663e084f31daf75977bd0753d2b19f4a4ff6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
